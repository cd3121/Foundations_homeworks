{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding surveillance planes using random forests\n",
    "\n",
    "**The story:**\n",
    "\n",
    "- https://www.buzzfeednews.com/article/peteraldhous/spies-in-the-skies\n",
    "- https://www.buzzfeednews.com/article/peteraldhous/hidden-spy-planes\n",
    "    \n",
    "This story, done by Peter Aldhous at Buzzfeed News, involved training a machine learning algorithm to recognize government surveillance planes based on what their flight patterns look like.\n",
    "\n",
    "**Topics:** Random Forests\n",
    "\n",
    "**Datasets**\n",
    "\n",
    "* **feds.csv:** Transponder codes of planes operated by the federal government\n",
    "* **planes_features.csv:** various features describing each plane's flight patterns\n",
    "* **train.csv:** a labeled dataset of transponder codes and whether each plane is a surveillance plane or not\n",
    "    - The `label` column was originally `class`, but I renamed it because pandas freaks out a bit with a column named `class`\n",
    "    - This was created by Buzzfeed `feds.csv`\n",
    "* **data dictionary:** You can find the data dictionary published with their analysis [here](https://buzzfeednews.github.io/2016-04-federal-surveillance-planes/analysis.html)\n",
    "* **a few other files**\n",
    "\n",
    "## What's the goal?\n",
    "\n",
    "The FBI and Department of Homeland Security operate many planes that are not directly labeled as belonging to the government. If we can uncover these planes, we have a better idea of the surveillance activities they are undertaking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Also set a large number of maximum columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.max_colwidth\", 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in our data\n",
    "\n",
    "Almost all classification problems start with a set of labeled features. In this case, the features are in one CSV file and the labels are in another. **Read both files in and merge them on `adshex`, the transpoder code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('data/planes_features.csv')\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('data/train.csv')\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No wait, merge them again!\n",
    "\n",
    "We have features for about 20,000 planes and labels for about 600 planes. When you merge, the planes you have features for but not labels for will disappear.\n",
    "\n",
    "We want to keep those in the dataframe so we can play detective with them later, and try to find surveillance planes using the features. When you merge, you should use `how='left'` or `how='right'` to keep unmatched columns from the left (or right) dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adshex = pd.merge(features, labels, on='adshex', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm you have 19,799 rows and 34 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adshex.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning up our data\n",
    "\n",
    "## Number-izing our labels\n",
    "\n",
    "Each row is a plane, and it's marked as either a surveillance plane or not. How many do we have in each category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adshex.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you feel about that split?\n",
    "\n",
    "**Prepare this column for machine learning.** What's wrong with it as `\"surveil\"` and `\"other\"`? Add a new column that we can use for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adshex['label'] = adshex.label.replace({'surveil': 1, 'other': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adshex.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical variables\n",
    "\n",
    "Do we have any variables that count as categories? Yes, we do! ...but how many different categories does it have?\n",
    "\n",
    "* **Tip:** You can use `.unique()` or `.value_counts()` to count unique items, depending on what you're looking for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adshex.type.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of those types of plane only have one appearance, which means they wouldn't be very helpful identifiers in the final analysis. For example, if I only see one GLF5 and it's a surveillance plane, does that mean the next one I see is probably a surveillance plane? With such a small sample size, I have no idea!\n",
    "\n",
    "We have a few options\n",
    "\n",
    "1. Create a very large set of dummy variables out of all 133 types of planes\n",
    "2. Create `0`/`1` columns for common plane types and ignore the less common ones -  C182, T206, SR22\n",
    "3. Interview someone who knows something about planes and put these into a few broader categories\n",
    "4. Keep them as one column, just turn them into numbers - it doesn't make sense in terms of order, but if one or two plane types are very indicative of a surveillance plane the forest might pick it up\n",
    "\n",
    "Oddly enough, **the last one is a common approach.** Let's use it!\n",
    "\n",
    "If you want to convert a list of categories into numbers, an easy way is to use the `Categorical` data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.type = df.type.astype('category')\n",
    "df.type.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like a normal bunch of strings, but pandas is secretly using a number for each one! You can find the number with `.cat.codes`.\n",
    "\n",
    "**Use `df.type.cat.codes` to make a new columns called `type_code`.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adshex['type_code'] = adshex.type.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adshex.type_code.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adshex.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use `type_code` for machine learning since sklearn needs a number, and `type` for reading since we like text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building our classifier\n",
    "\n",
    "When we're about to classify, we usually just drop our target column to build our inputs and outputs:\n",
    "\n",
    "```python\n",
    "X = train_df.drop(column='column_you_are_predicting')\n",
    "y = train_df.column_you_are_predicting\n",
    "```\n",
    "\n",
    "This time is a little different. First, we have unlabeled data in there! Use `.dropna()` to filter your training data so we only have labeled data.\n",
    "\n",
    "Confirm `train_df` has 597 rows and 35 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = adshex.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['adshex', 'type'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have a few extra columns that we aren't using for classification (like the text version of the type column and the transponder code). It's fine to drop multiple columns here that you aren't using, just a little bit messier. You also have to make sure you're dropping all the right ones.\n",
    "\n",
    "Do a `.head()` to double-check all of the columns you need to drop when creating your `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create your `X` and `y`.\n",
    "\n",
    "When you do `train_df.drop`, you'll want to remove more than just your `0`/`1` surveillance label. What other columns do you not want to use as input? Maybe some categories you converted into codes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['adshex', 'type'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Triple-check that `X` is a list of numeric features and and `y` is a numeric label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std \n",
    "\n",
    "X = train_df.drop(columns='label')\n",
    "y = train_df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into test and train datasets\n",
    "\n",
    "We could be nice and lazy and use all our data for training, but it just isn't right! Taking a test using the exact same questions you studied is just cheating. Split your data into test and train.\n",
    "\n",
    "* **Tip:** Don't do this manually! There's a method for it in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "\n",
    "# clf = tree.DecisionTreeClassifier(max_depth=5)\n",
    "# clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify using a logistic classifier\n",
    "\n",
    "## Train your classifier\n",
    "\n",
    "Build a `LogisticRegression` and fit it to your data, making sure you're training using only `X_train` and `y_train`.\n",
    "\n",
    "* **Tip:** You'll want to give `LogisticRegression` an extra argument of `max_iter=4000` - it means \"work a little harder than you expect,\" because otherwise it won't find an answer (by default it only has a `max_iter` of 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C=1e9, solver='lbfgs', max_iter=4000)\n",
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X.columns\n",
    "coefficients = clf.coef_[0]\n",
    "\n",
    "pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'coefficient (log odds ratio)': coefficients,\n",
    "    'odds ratio': np.exp(coefficients)\n",
    "}).sort_values(by='odds ratio', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the coefficients\n",
    "\n",
    "What does it mean? What features is the classifier using? Do you care about the odds ratio? **What is even the point of this `LogisticRegression` thing?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "feature_names = X.columns\n",
    "coefficients = clf.coef_[0]\n",
    "\n",
    "pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'coefficient (log odds ratio)': coefficients,\n",
    "    'odds ratio': np.exp(coefficients)\n",
    "}).sort_values(by='odds ratio', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How well does our classifier perform?\n",
    "\n",
    "Let's take a look at the confusion matrix to see how well this classifier finds surveillance planes.\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = y_test\n",
    "y_pred = clf.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['not surveil', 'surveil'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names)\n",
    "```\n",
    "\n",
    "Notice we're using `y_test` and `X_test`, not the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = y_test\n",
    "y_pred = clf.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['not surveil', 'surveil'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we use `y_test` and `X_test` instead of the full dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to see how good the training data trained our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify using a decision tree\n",
    "\n",
    "Now we'll use a decision tree. This is how you make one:\n",
    "\n",
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "```\n",
    "\n",
    "But it's up to you to teach it what spy planes look like using your training data.\n",
    "\n",
    "If we use `max_depth=` to limit the depth of the tree, it will help us visualize it. For example, `max_depth=5` will only allow the tree to make five decisions.\n",
    "\n",
    "Make a decision tree and fit it to your data. Use a `max_depth=` of something between 2 to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_depth=5)\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the important features?\n",
    "\n",
    "This code is slightly different than feature importance for logistic regression. It looks like this:\n",
    "\n",
    "```python\n",
    "feature_names = X.columns\n",
    "importances = clf.feature_importances_\n",
    "\n",
    "pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'feature importance': importances,\n",
    "}).sort_values(by='feature importance', ascending=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X.columns\n",
    "importances = clf.feature_importances_\n",
    "\n",
    "pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'feature importance': importances,\n",
    "}).sort_values(by='feature importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the output\n",
    "\n",
    "**Why is the feature importance difference than for logistic regression?**\n",
    "\n",
    "Also, if you don't specify a `max_depth`, that's a LOT of zeroes! It doesn't even use most of the features! **Why not?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How well does the tree perform?\n",
    "\n",
    "Display another confusion matrix with your new classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_test\n",
    "y_pred = clf.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['not surveil', 'surveil'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the tree\n",
    "\n",
    "You can use this code to visualize the tree. You might need to `brew install graphviz` and `pip install graphviz`.\n",
    "\n",
    "```python\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "\n",
    "label_names = ['not surveillance', 'surveillance']\n",
    "feature_names = X.columns\n",
    "\n",
    "dot_data = tree.export_graphviz(clf,\n",
    "                    feature_names=feature_names,  \n",
    "                    filled=True,\n",
    "                    class_names=label_names)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph\n",
    "```\n",
    "\n",
    "* **Tip:** You'll probably need to scroll sideways a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import graphviz\n",
    "\n",
    "label_names = ['not surveillance', 'surveillance']\n",
    "feature_names = X.columns\n",
    "\n",
    "dot_data = tree.export_graphviz(clf,\n",
    "                    feature_names=feature_names,  \n",
    "                    filled=True,\n",
    "                    class_names=label_names)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One more classifier: Random forest\n",
    "\n",
    "## Build and train your classifier\n",
    "\n",
    "We can build a random forest classifier like this:\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "```\n",
    "\n",
    "But you're in charge of fitting it to your training data!\n",
    "\n",
    "* **Tip:** You can also set `max_depth` here, but you won't be able to visualize the result.\n",
    "* **Tip:** Increase `n_estimators` to 100 to make a better classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 100, max_depth=5)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the important features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X.columns\n",
    "importances = clf.feature_importances_\n",
    "\n",
    "pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'feature importance': importances,\n",
    "}).sort_values(by='feature importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the output\n",
    "\n",
    "What is a random forest, and **why is the feature importance difference than for the decision tree?** Isn't a random forest just like a decision tree or something?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a random forest is just a bunch of trees - and every tree has his own results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How well does it perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_pred=model.predict(X_test)\n",
    "\n",
    "print('Accuracy:', metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How confident do you feel in the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I think we have overfitting here, because the accuracy is almost 100 percent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actually finding spy planes\n",
    "\n",
    "Now let's try ot actually find our spy planes\n",
    "\n",
    "## Retrain our model\n",
    "\n",
    "When we did test/train split, we trained our model with only a subset of our data, so we could test with the rest. Now that we're working in the \"real world\" we want to re-train it using not just `_train` and `_test` data, but instead **everything we have labels for.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 100, max_depth=5)\n",
    "clf = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter for planes we want to predict\n",
    "\n",
    "We have a dataframe of features that includes three types of planes:\n",
    "\n",
    "* Those that are labeled as surveillance planes\n",
    "* Those that are labeled as not surveillance\n",
    "* Those that aren't labeled\n",
    "\n",
    "Which do we want to predictions for? **Filter a new dataframe that's just those.**\n",
    "\n",
    "* **Tip:** Scroll up to see where you created your `train_df`, it's the opposite!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = adshex[adshex.label.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many planes do you have in that list? **Confirm it's about 19,200.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting \n",
    "\n",
    "Build your `X` - remember you need to drop a few columns - and use that to make a prediction for each plane.\n",
    "\n",
    "**Assign the prediction into the `predicted` column**.\n",
    "\n",
    "* **Tip:** Scroll up to see where you created your features for training, it's similar\n",
    "* **Tip:** pandas will yell at us about setting values on copies of a slice but it's fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df.drop(columns=['label', 'adshex', 'type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['predicted'] = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[X['predicted'] == 1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many planes did it predict to be surveillance planes?\n",
    "\n",
    "It should be roughly around 70-80 planes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[X['predicted'] == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But.. what about those other ones? The ones that are just below the threshold?\n",
    "\n",
    "The cutoff for a prediction of `1` is 50%, but since we have a lot of time we're interested in investigating the top 150. To get the probability for each row, you will use `clf.predict_proba` instead of `clf.predict`. Also, to get the predicted probability for the `1` category, you'll need to add `[:,1]` to the end of the\n",
    "\n",
    "```python\n",
    "clf.predict_proba(***your features***)[:,1]\n",
    "```\n",
    "\n",
    "**Create a new column called `predicted_prob` that is the chance that the plane is a surveillance plane.**\n",
    "\n",
    "* **Tip:** You dropped three columns when using `clf.predict`, but if you drop the same three you'll get an error now. There's now an extra column that you'll need to drop! What is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=['predicted'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['predicted_prob'] = clf.predict_proba(X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.predicted_prob.value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the top 200 predictions\n",
    "\n",
    "Take a look at what the probabilities look like, showing the top 200 planes that are **most likely to be surveillance planes.**\n",
    "\n",
    "Then save them to a file for later research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = X.sort_values(by='predicted_prob', ascending=False).head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('spy_planes', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spy_planes')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "What kind of machine learning are we doing here, and why are we doing it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are doing decision trees (random forest); it helps us classify if the planes in the dataset are spy planes or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "What are a few different ways you can deal with categorical data? Think about how we dealt with race in the reveal regression compared to how we dealt with type in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can either use a logistic regression or a decision tree (random forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Every time we ran a machine learning algorithm on our dataset, we looked at feature importance.\n",
    "\n",
    "* When might it be important to explain what our model found important?\n",
    "* When might it not be important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A feature is “important” if shuffling its values increases the model error, because in this case the model relied on the feature for the prediction.\n",
    "# A feature is “unimportant” if shuffling its values leaves the model error unchanged, because in this case the model ignored the feature for the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Using words and not column names, describe what the machine learning algorithm found to be important when identifying surveillance planes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the most important variables seem to be: the four-digit code transmitted by the transponder; the compass bearing\n",
    "# and the duration of the flight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Why did we use test/train split when it would have been more effective to give our model all of the data from the start?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when we don't have test data we can't be sure that our model is well doing (after it's created) - to test the model we need \"unused\" test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Why did we use a random forest instead of a decision tree or logistic regression? Was there something about the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generally we can say:\n",
    "# When the independent variables (features) are categorical, random forest tends to perform better than logistic regression.\n",
    "# With continuous variables, logistic regression is usually better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "Why did we use probability instead of just looking for planes with a predicted value of 1? It seems like we should have just trusted the algorithm, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because we had in a big data set only around 70 planes with a predicted value of 1. \n",
    "# But there are sure more spy planes: With the probability we can approach the truth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "What if our random forest or input dataset were flawed? What would be the repercussions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when the data is flawed then this is the same for the model. So the model would be flawed too. \n",
    "# the accuracy would be low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "The government could claim that we're threatening national security by publishing this paper as well as publishing this code - now anyone could look for planes that are surveilling them. What do you think?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we live in a democracy - the people elect and pay the gouvernment; so the people have a right to know if they are \n",
    "# spyed or not. \n",
    "# even better if people reproduce this work; so they can be aware of the spying gouvernment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "We're using data from the past, but you can get real-time flight data from many services. Can you think of any uses for this algorithm using real-time instead of historical data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when we would use real-time data it would be better to change the model: to a logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "This isn't a question, but if you look at `candidates.csv` and `candidates-annotates.csv` you can see how Buzzfeed did their research after finding a list of suspicious planes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
